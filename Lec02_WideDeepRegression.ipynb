{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec02_WideDeepRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "428ce3a6ff234f8c976c76c39575b9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de444883f222495497bb3b89fd40a9a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d8137d349454e299dbb04a3d71665cd",
              "IPY_MODEL_f1f98ee22e4e423995d8cb7f34a0ab5b"
            ]
          }
        },
        "de444883f222495497bb3b89fd40a9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d8137d349454e299dbb04a3d71665cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_824ff573625d4a549f2e2897b1bce2f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39638978af374d5d959c071b2cd50b19"
          }
        },
        "f1f98ee22e4e423995d8cb7f34a0ab5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c203e0eea6934374a26e1b6b22fd05c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 38793976.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e10b02c489c4cc7a0b9845b41aac8c3"
          }
        },
        "824ff573625d4a549f2e2897b1bce2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39638978af374d5d959c071b2cd50b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c203e0eea6934374a26e1b6b22fd05c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e10b02c489c4cc7a0b9845b41aac8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96da44880a35480d99d1364f875d1029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07ccf27ebfda4d0fac3c4822206b6e0d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_032eebf442b342fc81b022cca83ef7aa",
              "IPY_MODEL_157e11850c584718b58573feed9d20f1"
            ]
          }
        },
        "07ccf27ebfda4d0fac3c4822206b6e0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "032eebf442b342fc81b022cca83ef7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_65436eaa3d6e47feadb6f08f6f096863",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ccd48841fe0483490b589e0707c23bc"
          }
        },
        "157e11850c584718b58573feed9d20f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4f38c7769fc4357831aa6474f1ca721",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 850877.84it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9da4d50b5fe34f4f877e31582f5742c2"
          }
        },
        "65436eaa3d6e47feadb6f08f6f096863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ccd48841fe0483490b589e0707c23bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4f38c7769fc4357831aa6474f1ca721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9da4d50b5fe34f4f877e31582f5742c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e983dd613a104e1e9ed27c8494ed2236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e52a2bc785a481399d946e398395880",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1482135664a24559941c0002225ccf64",
              "IPY_MODEL_b932547550f44578a91f3a423f5289b0"
            ]
          }
        },
        "5e52a2bc785a481399d946e398395880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1482135664a24559941c0002225ccf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2210167fe4024b5da61c25585e79cf26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_605447acd66b4449af3f55c1b27b7027"
          }
        },
        "b932547550f44578a91f3a423f5289b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37d0ff364c6a4646b92252cdb6324671",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:12&lt;00:00, 135656.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d5bd4ea0c534fa6bba42deb3b37215b"
          }
        },
        "2210167fe4024b5da61c25585e79cf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "605447acd66b4449af3f55c1b27b7027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37d0ff364c6a4646b92252cdb6324671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d5bd4ea0c534fa6bba42deb3b37215b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f074104e64f7443cab660aaf8065984d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1bd9ee910d9448a1b02924d29bc13a3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a40ee4730ab74ed0929dff362b9cc450",
              "IPY_MODEL_61b4b77c3e6543fa88a21cfb139d3020"
            ]
          }
        },
        "1bd9ee910d9448a1b02924d29bc13a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a40ee4730ab74ed0929dff362b9cc450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9280ff1c17af4c7cb8ff12d81d5ba4a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4f47d36b1bf4b7da9c112fb299a72f8"
          }
        },
        "61b4b77c3e6543fa88a21cfb139d3020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce44c96be4214d399ef261abdea1afad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:11&lt;00:00, 442.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20fc1a67d30e4f63b43418a9af66da50"
          }
        },
        "9280ff1c17af4c7cb8ff12d81d5ba4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4f47d36b1bf4b7da9c112fb299a72f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce44c96be4214d399ef261abdea1afad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20fc1a67d30e4f63b43418a9af66da50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yugi-Seong/CNN/blob/main/Lec02_WideDeepRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPYPTlOubhVd"
      },
      "source": [
        "## Codes are adapted from SungKim@HKUST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiH1ryROrPbJ",
        "outputId": "62551898-5cd5-4234-81ca-9eeb7faf1857"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR2-JgxorRjC",
        "outputId": "8e431f04-b8e4-4fce-fc8a-c7cfa4871ed0"
      },
      "source": [
        "cd '/content/drive/MyDrive/CNN'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2wLF9BOOM2g"
      },
      "source": [
        "## 01. Wide and Deep Model (Diabets_logistic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GmQTWVFr-qK"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hg-I4bqsAqW",
        "outputId": "1d6a213d-1342-497e-a378-f8aa628c8b00"
      },
      "source": [
        "xy = np.loadtxt('data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
        "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
        "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
        "\n",
        "print(x_data.data.shape)\n",
        "print(y_data.data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([759, 8])\n",
            "torch.Size([759, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nllZAYaWsDNF"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self): # train 하고자 하는 weight의 모듈이 존재\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear module\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(8, 5)\n",
        "        self.l2 = torch.nn.Linear(5, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred\n",
        "\n",
        "# our model\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1E9UxaMsFZz",
        "outputId": "fc2118b8-e58f-4f08-da08-f3702b2f51a6"
      },
      "source": [
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters of the two\n",
        "# nn.Linear modules which are members of the model.\n",
        "\n",
        "criterion = torch.nn.BCELoss(size_average=True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5E1JIGHsHic",
        "outputId": "c1abe5e8-d565-4053-d808-e6e1ece54f75"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(100):\n",
        "        # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(epoch, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6579359769821167\n",
            "1 0.656880795955658\n",
            "2 0.6559155583381653\n",
            "3 0.6550320982933044\n",
            "4 0.6542235612869263\n",
            "5 0.6534832119941711\n",
            "6 0.6528052091598511\n",
            "7 0.6521841287612915\n",
            "8 0.6516149640083313\n",
            "9 0.6510933637619019\n",
            "10 0.6506152749061584\n",
            "11 0.6501768827438354\n",
            "12 0.6497747898101807\n",
            "13 0.6494059562683105\n",
            "14 0.6490675806999207\n",
            "15 0.6487571001052856\n",
            "16 0.6484720706939697\n",
            "17 0.6482104659080505\n",
            "18 0.6479702591896057\n",
            "19 0.6477496027946472\n",
            "20 0.6475470066070557\n",
            "21 0.6473608016967773\n",
            "22 0.6471897959709167\n",
            "23 0.647032618522644\n",
            "24 0.6468881964683533\n",
            "25 0.6467553377151489\n",
            "26 0.6466332077980042\n",
            "27 0.6465209722518921\n",
            "28 0.6464176177978516\n",
            "29 0.6463226675987244\n",
            "30 0.6462351679801941\n",
            "31 0.6461548209190369\n",
            "32 0.6460808515548706\n",
            "33 0.6460126638412476\n",
            "34 0.6459499597549438\n",
            "35 0.6458922028541565\n",
            "36 0.6458390355110168\n",
            "37 0.6457900404930115\n",
            "38 0.6457449197769165\n",
            "39 0.6457033157348633\n",
            "40 0.6456649303436279\n",
            "41 0.6456296443939209\n",
            "42 0.6455970406532288\n",
            "43 0.645566999912262\n",
            "44 0.6455393433570862\n",
            "45 0.6455137133598328\n",
            "46 0.6454901695251465\n",
            "47 0.6454683542251587\n",
            "48 0.6454483270645142\n",
            "49 0.6454296708106995\n",
            "50 0.6454125046730042\n",
            "51 0.6453966498374939\n",
            "52 0.6453819870948792\n",
            "53 0.6453684568405151\n",
            "54 0.6453558802604675\n",
            "55 0.6453442573547363\n",
            "56 0.645333468914032\n",
            "57 0.6453235149383545\n",
            "58 0.6453142762184143\n",
            "59 0.6453056931495667\n",
            "60 0.6452977061271667\n",
            "61 0.6452903747558594\n",
            "62 0.6452834606170654\n",
            "63 0.6452770829200745\n",
            "64 0.6452711224555969\n",
            "65 0.6452656388282776\n",
            "66 0.6452604532241821\n",
            "67 0.6452556252479553\n",
            "68 0.6452511548995972\n",
            "69 0.6452469229698181\n",
            "70 0.6452429890632629\n",
            "71 0.6452392935752869\n",
            "72 0.6452358961105347\n",
            "73 0.6452325582504272\n",
            "74 0.6452295184135437\n",
            "75 0.6452266573905945\n",
            "76 0.6452239751815796\n",
            "77 0.6452214121818542\n",
            "78 0.6452189087867737\n",
            "79 0.6452167630195618\n",
            "80 0.6452145576477051\n",
            "81 0.6452124714851379\n",
            "82 0.6452105045318604\n",
            "83 0.6452086567878723\n",
            "84 0.645206868648529\n",
            "85 0.6452051401138306\n",
            "86 0.6452035903930664\n",
            "87 0.6452019810676575\n",
            "88 0.6452004909515381\n",
            "89 0.6451990604400635\n",
            "90 0.6451976299285889\n",
            "91 0.6451963186264038\n",
            "92 0.6451950669288635\n",
            "93 0.6451937556266785\n",
            "94 0.645192563533783\n",
            "95 0.6451913714408875\n",
            "96 0.6451901793479919\n",
            "97 0.6451890468597412\n",
            "98 0.6451879739761353\n",
            "99 0.6451869010925293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQoffm7IqiAY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuUo2BJEvzDz"
      },
      "source": [
        "## 02. Diabet Classification Using Custom DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T--364TIwLjx"
      },
      "source": [
        "# References\n",
        "# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/pytorch_basics/main.py\n",
        "# http://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sajsCh4RwLmZ"
      },
      "source": [
        "class DiabetesDataset(Dataset):\n",
        "    \"\"\" Diabetes dataset.\"\"\"\n",
        "\n",
        "    # Initialize your data, download, etc.\n",
        "    def __init__(self):\n",
        "        xy = np.loadtxt('./data/diabetes.csv.gz',\n",
        "                        delimiter=',', dtype=np.float32)\n",
        "        self.len = xy.shape[0]\n",
        "        self.x_data = torch.from_numpy(xy[:, 0:-1])\n",
        "        self.y_data = torch.from_numpy(xy[:, [-1]])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCzMnjexwLpW"
      },
      "source": [
        "dataset = DiabetesDataset()\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh16GsZ-wLsJ"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear module\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(8, 6)\n",
        "        self.l2 = torch.nn.Linear(6, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred\n",
        "\n",
        "# our model\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b-Ej1BrwLvJ",
        "outputId": "546bfa68-c4aa-41df-aa94-c0ffed8ef484"
      },
      "source": [
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters of the two\n",
        "# nn.Linear modules which are members of the model.\n",
        "criterion = torch.nn.BCELoss(size_average=True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38wIbF3ZwLy7",
        "outputId": "4dafdb49-737f-41a6-f266-51eed851a80e"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(2):\n",
        "    for i, data in enumerate(train_loader, 0): #dataloader = Iterator\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # wrap them in Variable\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        # Forward pass: Compute predicted y by passing x to the model\n",
        "        y_pred = model(inputs)\n",
        "\n",
        "        # Compute and print loss\n",
        "        loss = criterion(y_pred, labels)\n",
        "        print(epoch, i, loss.item())\n",
        "\n",
        "        # Zero gradients, perform a backward pass, and update the weights.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0.6622541546821594\n",
            "0 1 0.6104357838630676\n",
            "0 2 0.6330622434616089\n",
            "0 3 0.6764484643936157\n",
            "0 4 0.5589278936386108\n",
            "0 5 0.6448723673820496\n",
            "0 6 0.6947207450866699\n",
            "0 7 0.6288655996322632\n",
            "0 8 0.59519362449646\n",
            "0 9 0.6793532967567444\n",
            "0 10 0.6614611744880676\n",
            "0 11 0.6100084781646729\n",
            "0 12 0.6260972023010254\n",
            "0 13 0.6436702609062195\n",
            "0 14 0.6618838906288147\n",
            "0 15 0.6619544625282288\n",
            "0 16 0.6800180673599243\n",
            "0 17 0.6437458992004395\n",
            "0 18 0.5546901822090149\n",
            "0 19 0.6815656423568726\n",
            "0 20 0.7374595403671265\n",
            "0 21 0.6616527438163757\n",
            "0 22 0.748808741569519\n",
            "0 23 0.5800150036811829\n",
            "1 0 0.6442949771881104\n",
            "1 1 0.6440621614456177\n",
            "1 2 0.5375999808311462\n",
            "1 3 0.6238345503807068\n",
            "1 4 0.6429299116134644\n",
            "1 5 0.6036394834518433\n",
            "1 6 0.5825416445732117\n",
            "1 7 0.6016956567764282\n",
            "1 8 0.6649593114852905\n",
            "1 9 0.6642234921455383\n",
            "1 10 0.6639039516448975\n",
            "1 11 0.6224679946899414\n",
            "1 12 0.622360110282898\n",
            "1 13 0.6225181221961975\n",
            "1 14 0.6430814266204834\n",
            "1 15 0.6219834685325623\n",
            "1 16 0.6433320045471191\n",
            "1 17 0.6645122170448303\n",
            "1 18 0.643157958984375\n",
            "1 19 0.7269592881202698\n",
            "1 20 0.7819309830665588\n",
            "1 21 0.7166396379470825\n",
            "1 22 0.6962954998016357\n",
            "1 23 0.6001272797584534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DG4BnLRqiFc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO3PzBL27Awr"
      },
      "source": [
        "## 03. Softmax Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiyulabEqiHs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYDwlcf_7WVI",
        "outputId": "8cf245a4-8379-45dc-b475-dfbf9d96308c"
      },
      "source": [
        "# Cross entropy example\n",
        "import numpy as np\n",
        "# One hot\n",
        "# 0: 1 0 0\n",
        "# 1: 0 1 0\n",
        "# 2: 0 0 1\n",
        "Y = np.array([1, 0, 0])\n",
        "\n",
        "Y_pred1 = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred2 = np.array([0.1, 0.3, 0.6])\n",
        "print(\"loss1 = \", np.sum(-Y * np.log(Y_pred1)))\n",
        "print(\"loss2 = \", np.sum(-Y * np.log(Y_pred2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss1 =  0.35667494393873245\n",
            "loss2 =  2.3025850929940455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XyK47Zh7btu"
      },
      "source": [
        "# Softmax + CrossEntropy (logSoftmax + NLLLoss)\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJgR4jNf7fhx"
      },
      "source": [
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "Y = Variable(torch.LongTensor([0]), requires_grad=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAbsi8wX7jtD"
      },
      "source": [
        "# input is of size nBatch x nClasses = 1 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred1 = Variable(torch.Tensor([[2.0, 1.0, 0.1]]))\n",
        "Y_pred2 = Variable(torch.Tensor([[0.5, 2.0, 0.3]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt_QMCmR7mQH",
        "outputId": "c82a360c-5863-43d5-dbf6-689b759f79f6"
      },
      "source": [
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "\n",
        "print(\"PyTorch Loss1 = \", l1.data, \"\\nPyTorch Loss2=\", l2.data)\n",
        "\n",
        "print(\"Y_pred1=\", torch.max(Y_pred1.data, 1)[1])\n",
        "print(\"Y_pred2=\", torch.max(Y_pred2.data, 1)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Loss1 =  tensor(0.4170) \n",
            "PyTorch Loss2= tensor(1.8406)\n",
            "Y_pred1= tensor([0])\n",
            "Y_pred2= tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMH4T_b-7pUt"
      },
      "source": [
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "Y = Variable(torch.LongTensor([2, 0, 1]), requires_grad=False)\n",
        "\n",
        "# input is of size nBatch x nClasses = 2 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred1 = Variable(torch.Tensor([[0.1, 0.2, 0.9],\n",
        "                                 [1.1, 0.1, 0.2],\n",
        "                                 [0.2, 2.1, 0.1]]))\n",
        "\n",
        "\n",
        "Y_pred2 = Variable(torch.Tensor([[0.8, 0.2, 0.3],\n",
        "                                 [0.2, 0.3, 0.5],\n",
        "                                 [0.2, 0.2, 0.5]]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYzH5rM_7zdW",
        "outputId": "2aa8a469-075d-451e-9f5b-e4521a3beea5"
      },
      "source": [
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "\n",
        "print(\"Batch Loss1 = \", l1.data, \"\\nBatch Loss2=\", l2.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Loss1 =  tensor(0.4966) \n",
            "Batch Loss2= tensor(1.2389)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3DiU2h7qiMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9lD4np79TbV"
      },
      "source": [
        "## 04.Softmax Classifier Using MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygFt6RQh9Stn"
      },
      "source": [
        "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-7I0Hw09ef-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "428ce3a6ff234f8c976c76c39575b9a3",
            "de444883f222495497bb3b89fd40a9a7",
            "7d8137d349454e299dbb04a3d71665cd",
            "f1f98ee22e4e423995d8cb7f34a0ab5b",
            "824ff573625d4a549f2e2897b1bce2f7",
            "39638978af374d5d959c071b2cd50b19",
            "c203e0eea6934374a26e1b6b22fd05c1",
            "0e10b02c489c4cc7a0b9845b41aac8c3",
            "96da44880a35480d99d1364f875d1029",
            "07ccf27ebfda4d0fac3c4822206b6e0d",
            "032eebf442b342fc81b022cca83ef7aa",
            "157e11850c584718b58573feed9d20f1",
            "65436eaa3d6e47feadb6f08f6f096863",
            "3ccd48841fe0483490b589e0707c23bc",
            "a4f38c7769fc4357831aa6474f1ca721",
            "9da4d50b5fe34f4f877e31582f5742c2",
            "e983dd613a104e1e9ed27c8494ed2236",
            "5e52a2bc785a481399d946e398395880",
            "1482135664a24559941c0002225ccf64",
            "b932547550f44578a91f3a423f5289b0",
            "2210167fe4024b5da61c25585e79cf26",
            "605447acd66b4449af3f55c1b27b7027",
            "37d0ff364c6a4646b92252cdb6324671",
            "1d5bd4ea0c534fa6bba42deb3b37215b",
            "f074104e64f7443cab660aaf8065984d",
            "1bd9ee910d9448a1b02924d29bc13a3a",
            "a40ee4730ab74ed0929dff362b9cc450",
            "61b4b77c3e6543fa88a21cfb139d3020",
            "9280ff1c17af4c7cb8ff12d81d5ba4a2",
            "b4f47d36b1bf4b7da9c112fb299a72f8",
            "ce44c96be4214d399ef261abdea1afad",
            "20fc1a67d30e4f63b43418a9af66da50"
          ]
        },
        "outputId": "34a47375-1f2a-4f34-bb8c-6f92f2e90777"
      },
      "source": [
        "# Training settings\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)  # data 폴더 안에 MNIST dataset이 다운로드 됨 \n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "428ce3a6ff234f8c976c76c39575b9a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96da44880a35480d99d1364f875d1029",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e983dd613a104e1e9ed27c8494ed2236",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f074104e64f7443cab660aaf8065984d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Processing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GExnc789hCo"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 520)\n",
        "        self.l2 = nn.Linear(520, 320)\n",
        "        self.l3 = nn.Linear(320, 240)\n",
        "        self.l4 = nn.Linear(240, 120)\n",
        "        self.l5 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784) -> fully connected layer 에 넣음 #batch size 또는 64 대신 -1 을 입력해도 알아서 64가 입력됨\n",
        "        # x = x.view(64, -1) \n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        return self.l5(x)\n",
        "\n",
        "\n",
        "model = Net()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq_d-tHn9mEQ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZJH0bac9mGw"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train() # gradient 모두 사용\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEycEey69hFB"
      },
      "source": [
        "def test():\n",
        "    model.eval() #gradient 계산 안함 \n",
        "    test_loss = 0\n",
        "    correct = 0 #정확도 \n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).item()\n",
        "        # get the index of the max\n",
        "        pred = output.data.max(1, keepdim=True)[1] # max함수를 이용해 최댓값을 찾아 냄 \n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBkMRjF-9qMg",
        "outputId": "0b03d35a-0b2e-40a0-b2b4-636a9cbc8e87"
      },
      "source": [
        "for epoch in range(1, 10):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300640\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.305988\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.302471\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.303741\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295113\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.305640\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.299979\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.300575\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.306004\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.299477\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.303007\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.304554\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.292244\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.296706\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.298670\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.303335\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.305578\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.298925\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.296420\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.296590\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.290610\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.297057\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.289981\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.299317\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.287914\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.290719\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.293243\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.302406\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.297311\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.290705\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.295177\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.292994\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.284628\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.288080\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.296123\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.288794\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.289366\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.287420\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.289934\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.289367\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.289592\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.283784\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.286072\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.285371\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.287894\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.284863\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.280779\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.280310\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.265487\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.278141\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.270815\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.265314\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.273239\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.276316\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.276534\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.275550\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.270728\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.273202\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.262858\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.267965\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.265551\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.240165\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.242710\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.235956\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.255902\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.241334\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.229922\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.218042\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 2.213497\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.236283\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.206796\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.202232\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.186489\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.164692\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.161992\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.159220\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.133398\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.114332\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.034144\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.080544\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.066104\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.984771\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.041552\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.909204\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.049968\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.907166\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.916030\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.970334\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.921563\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.803500\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.876376\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.629422\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.771640\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.822137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0260, Accuracy: 5049/10000 (50%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.559411\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.605780\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.538361\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.530875\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.697045\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.499442\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.295656\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 1.225676\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.363967\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 1.250846\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.391176\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 1.277794\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.285415\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.982104\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.933523\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.122081\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.929894\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.895440\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.789926\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 1.040245\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.029891\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.020705\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.948064\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.844996\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.819914\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.764807\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.779572\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.607065\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.782498\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.765463\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.800570\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.482362\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.607752\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.754695\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.759832\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.688074\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.551976\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.551791\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.518939\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.866508\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.577285\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.764550\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.602795\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.683118\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.591254\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.522457\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.146390\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.619067\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.480596\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.601415\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.804095\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.565457\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.574136\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.461720\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.744771\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.505629\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.787429\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.440874\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.572131\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.434209\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.550475\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.536445\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.688257\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.471841\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.599090\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.618010\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.670727\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.478999\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.567953\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.614558\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.574247\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.702778\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.849209\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.023332\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.396559\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.496106\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.604171\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.551760\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.441759\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.488949\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.488794\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.299809\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.347041\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.710933\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.591742\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.657944\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.293861\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.587833\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.462194\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.293348\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.385285\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.554330\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.385956\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.326083\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 8685/10000 (87%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.429880\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.529339\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.341788\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.712024\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.526613\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.333386\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.471337\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.351126\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.595014\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.331668\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.736328\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.509756\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.454394\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.463099\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.610476\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.299668\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.394131\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.438743\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.300473\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.502116\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.606832\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.382798\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.526113\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.629272\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.438490\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.308654\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.354080\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.335432\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.330097\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.221588\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.353204\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.419070\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.313948\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.441283\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.407115\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.313898\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.259219\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.419485\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.470122\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.392332\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.227657\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.248670\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.508517\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.388242\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.320629\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.333208\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.422992\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.458854\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.171906\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.348237\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.301324\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.254250\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.316608\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.386998\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.257059\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.413841\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.522696\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.214992\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.307234\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.279075\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.370581\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.433282\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.318594\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.357104\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.317227\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.236662\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.404828\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.207471\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.246877\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.352409\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.354276\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.383823\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.296324\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.345596\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.163721\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.334878\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.219512\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.430759\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.457084\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.165099\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.366161\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.363604\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.273579\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.327777\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.278759\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.300270\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.544016\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.240580\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.240365\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.462384\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.302987\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.400777\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.493021\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.436613\n",
            "\n",
            "Test set: Average loss: 0.0045, Accuracy: 9155/10000 (92%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.244384\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.232317\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.186146\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.230704\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.373817\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.211467\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.345259\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.270307\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.327688\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.337846\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.178243\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.122686\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.268178\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.190941\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.233136\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.569720\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.252696\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.205162\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.195515\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.268672\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.161262\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.224961\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.198550\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.246770\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.149850\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.257202\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.234817\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.227924\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.270959\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.281837\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.211247\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.401152\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.131043\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.286452\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.433507\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.222579\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.604169\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.443779\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.194218\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.433432\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.266208\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.240112\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.185325\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.312646\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.205163\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.211630\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.375300\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.289135\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.349272\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.241750\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.202783\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.198997\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.184070\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.290427\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.223644\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.425450\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.311454\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.352414\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.230663\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.212913\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.172785\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.249062\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.504986\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.342858\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.323067\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.317571\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.446055\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.476202\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.099066\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.201843\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.209909\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.183330\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.394426\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.127421\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.285525\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.271887\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.173200\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.199642\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.200993\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.350877\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.381512\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.325927\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.497131\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.085228\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.203687\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.204357\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.423657\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.285292\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.116800\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.415195\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.143676\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.219742\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.262075\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.294972\n",
            "\n",
            "Test set: Average loss: 0.0036, Accuracy: 9283/10000 (93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.198284\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.302941\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.251697\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.215827\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.090199\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.442669\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.137776\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.137489\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.193108\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.141098\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.157340\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.259519\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.421504\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.310638\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.241217\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.108058\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.078228\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.398795\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.354629\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.238429\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.266376\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.250323\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.242091\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.227554\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.128964\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.365876\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.138389\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.199324\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.148158\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.107557\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.203939\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.126606\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.220385\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.167027\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.184649\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.139502\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.242499\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.241637\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.138071\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.086894\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.223715\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.067543\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.267265\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.086231\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.141629\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.200248\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.165619\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.249712\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.426753\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.230094\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.129410\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.154298\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.131233\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.125305\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.224065\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.315133\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.176763\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.142923\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.148019\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.222491\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.178979\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.112724\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.039090\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.166888\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.204159\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.152234\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.122788\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.192460\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.122782\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.181099\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.302434\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.208978\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.098925\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.227311\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.130316\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.078707\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.086337\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.255233\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.149670\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.301724\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.199334\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.257892\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.121856\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.088782\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.121076\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.106690\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.071958\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.103797\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.062304\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.196667\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.166189\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.202097\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.078828\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.118787\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9426/10000 (94%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.209647\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.284716\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.134423\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.116942\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.178878\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.300843\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.263517\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.148845\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.129154\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.213998\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.045934\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.302952\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.158728\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.140183\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.296096\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.123043\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.187061\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.140309\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.258397\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.078771\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.084219\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.124836\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.095279\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.064477\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.194365\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.030906\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.124116\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.166692\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.189532\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.130710\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.138285\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.104379\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.176552\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.113292\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.140019\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.182075\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.165984\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.107837\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.045204\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.118133\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.216174\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.103119\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.097550\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.073779\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.117295\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.190185\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.216114\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.055107\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.113140\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.206468\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.146874\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.221939\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.230548\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.141467\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.137882\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.101170\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.146977\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.250306\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.068526\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.119146\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.180342\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.125025\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.074624\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.098523\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.111459\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.116252\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.496554\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.040306\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.112978\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.082273\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.075063\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.228580\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.066359\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.132012\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.144555\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.034962\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.134910\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.121862\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.140301\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.160217\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.092837\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.072559\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.228118\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.132350\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.059470\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.090555\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.198343\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.106649\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.118359\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.032623\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.134622\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.134081\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.226113\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.170438\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9502/10000 (95%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.227238\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.214014\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.062657\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.071282\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.117037\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.247597\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.062034\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.253755\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.086193\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.130835\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.061293\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.096756\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.155840\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.129167\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.190818\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.122728\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.187108\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.164283\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.104745\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.274648\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.079315\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.124643\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.167967\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.098582\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.073374\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.157829\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.133567\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.151386\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.182189\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.077492\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.451273\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.144650\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.267042\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.198702\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.085852\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.124223\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.068766\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.299361\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.314208\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.049974\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.059769\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.167278\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.166630\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.188111\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.197904\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.080181\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.210015\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.098257\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.114729\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.119347\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.040358\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.069071\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.083712\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.192486\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.078337\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.013647\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.193378\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.252071\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.039084\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.224876\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.122542\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.196294\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.114040\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.102989\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.151317\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.126528\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.140219\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.125219\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.107374\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.164192\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.107560\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.073918\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.085104\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.106794\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.067906\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.104766\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.070516\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.133599\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.068641\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.355602\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.109645\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.179561\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.078166\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.059176\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.084147\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.096401\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.235314\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.171621\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.078629\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.100599\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.094227\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.028146\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.102958\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.079510\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.130761\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.170399\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.211056\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.134272\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.049968\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.151344\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.055734\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.073924\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.140882\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.109131\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.210232\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.087652\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.109008\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.149896\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.106096\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.186470\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.113629\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.302883\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.069121\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.087275\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.145780\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.012013\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.128117\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.154716\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.153548\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.303963\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.165263\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.055575\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.161530\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.100194\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.090505\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.067306\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.143318\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.063109\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.097090\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.027239\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.274428\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.126631\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.140395\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.186640\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.128679\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.107354\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.062556\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.138951\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.308420\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.101242\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.155533\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.120645\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.221312\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.023490\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.266861\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.263764\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.223528\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.215190\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.060509\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.231382\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.024167\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.214010\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.112463\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.030760\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.053305\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.045045\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.224783\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.056068\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.052856\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.044256\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.123149\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.123521\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.087438\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.157039\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.060243\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.258042\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.164643\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.104058\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.165969\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.029963\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.046475\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.048979\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.042232\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.074361\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.113997\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.195166\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.090469\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.042525\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.135104\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.037150\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.099434\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.088158\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.094450\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.088330\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.075996\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.102097\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.087353\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.098333\n",
            "\n",
            "Test set: Average loss: 0.0020, Accuracy: 9620/10000 (96%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.067520\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.030649\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.052666\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.134283\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.048990\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.216917\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.056909\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.104537\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.054794\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.162766\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.251059\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.049825\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.027576\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.129072\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.042935\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.118754\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.054749\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.062363\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.046152\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.105096\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.037181\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.101007\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.052794\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.124532\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.058699\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.198245\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.153863\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.094485\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.137096\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.076109\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.043215\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.064404\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.076822\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.193134\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.077852\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.069017\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.107844\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.089730\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.052838\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.085910\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.035101\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.073068\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.057299\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.219426\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.106039\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.035416\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.057836\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.062856\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.023149\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.088537\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.093716\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.066374\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.097568\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.055906\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.069609\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.165684\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.068786\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.103661\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.087836\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.239846\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.080507\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.093143\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.199327\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.026662\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.129699\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.135528\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.258186\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.086219\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.080685\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.011927\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.106060\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.054226\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.084486\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.168307\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.027882\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.102803\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.202140\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.085473\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.078397\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.086100\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.057504\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.108233\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.129143\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.057325\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.179145\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.140319\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.057488\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.084871\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.174525\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.084021\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.187793\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.049241\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.158118\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.188495\n",
            "\n",
            "Test set: Average loss: 0.0019, Accuracy: 9631/10000 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd0xQk0z9ekn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCIUtpUlBoE0"
      },
      "source": [
        "## 03. Toy Inception MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge9Fla60BihQ"
      },
      "source": [
        "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RSCPF0BBij1"
      },
      "source": [
        "# Training settings\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3UTib-6BylC"
      },
      "source": [
        "class InceptionA(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "        super(InceptionA, self).__init__()\n",
        "        self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
        "\n",
        "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
        "        self.branch5x5_2 = nn.Conv2d(16, 24, kernel_size=5, padding=2)\n",
        "\n",
        "        self.branch3x3dbl_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
        "        self.branch3x3dbl_2 = nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
        "        self.branch3x3dbl_3 = nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
        "\n",
        "        self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "\n",
        "        branch5x5 = self.branch5x5_1(x)\n",
        "        branch5x5 = self.branch5x5_2(branch5x5)\n",
        "\n",
        "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
        "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
        "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
        "\n",
        "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
        "        branch_pool = self.branch_pool(branch_pool)\n",
        "\n",
        "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
        "        return torch.cat(outputs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhA6o_rVByoc"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(88, 20, kernel_size=5)\n",
        "\n",
        "        self.incept1 = InceptionA(in_channels=10)\n",
        "        self.incept2 = InceptionA(in_channels=20)\n",
        "\n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(1408, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = F.relu(self.mp(self.conv1(x)))\n",
        "        x = self.incept1(x)\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "        x = self.incept2(x)\n",
        "        x = x.view(in_size, -1)  # flatten the tensor\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEyjTSb-Byq0"
      },
      "source": [
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziWS8JL6B8WD"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWZb8OioB8Yi"
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhR86b-iCDJ-",
        "outputId": "978b5492-7fe2-4b1c-954c-80b53f08d050"
      },
      "source": [
        "for epoch in range(1, 10):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298459\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.302282\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.314808\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.313843\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.307911\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.301989\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.292517\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.291605\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.301653\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.293882\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.293476\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.288318\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.307489\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.282997\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.300429\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.278991\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.284487\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.271263\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.272692\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.256499\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.247248\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.219682\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.218287\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.199482\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.072562\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.018283\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.888470\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.645551\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.340695\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.054764\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.061440\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.708808\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.811880\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.733036\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.503645\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.691997\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.785598\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.522545\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.401532\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.630583\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.699138\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.406982\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.309511\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.654108\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.346521\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.403801\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.409148\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.310570\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.369544\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.326941\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.406885\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.450345\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.314456\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.545085\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.463935\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.441519\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.311745\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.264772\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.340990\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.511739\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.370371\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.217039\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.291192\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.268370\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.290411\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.244508\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.371804\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.264199\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.092484\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.421108\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.278990\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.351037\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.358358\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.330466\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.379456\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.236032\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.219422\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.173511\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.307927\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.441642\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.190848\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.349796\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.333977\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.300917\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.181879\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.231879\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.267939\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.222201\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.247269\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.274390\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.129102\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.319077\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.213508\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.375303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1995, Accuracy: 9402/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.258538\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.217049\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.169010\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.160412\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.413642\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.295826\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.261276\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.092610\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.242168\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.269855\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.191170\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.146693\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.315070\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.197020\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.235060\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.152280\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.170992\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.221109\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.164026\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.068481\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.227278\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.186990\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.070408\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.054403\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.130806\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.146219\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.068909\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.090442\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.097665\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.156443\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.238270\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.282475\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.075664\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.118699\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.116094\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.295763\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.090409\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.083746\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.155618\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.126978\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.150365\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.161991\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.207581\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.198018\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.152199\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.081553\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.158769\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.118967\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.286443\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.228006\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.193929\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.061845\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.199084\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.054408\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.171303\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.065156\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.119923\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.127407\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.121178\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.109711\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.133274\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.272783\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.238547\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.109010\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.251755\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.185380\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.152634\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.112453\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.052718\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.064517\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.171271\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.049186\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.142638\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.165405\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.190254\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.143566\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.082231\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.166204\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.157046\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.123517\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.281554\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.097073\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.117904\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.108541\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.087001\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.079952\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.159783\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.030979\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.129183\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.270887\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.094167\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.139767\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.175420\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.133328\n",
            "\n",
            "Test set: Average loss: 0.0993, Accuracy: 9669/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.170648\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.138560\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.086426\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.211556\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.107071\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.356113\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.062097\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.201259\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.106286\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.107792\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.103604\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.199347\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.062851\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.143251\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.084281\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.051504\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.026430\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.113778\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.129343\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.098869\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.240272\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.037645\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.088315\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.148072\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.127308\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.033290\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.089775\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.088010\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.160561\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.144199\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.094785\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.140886\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.065263\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.060500\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.122892\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.090418\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.095281\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.108139\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.141379\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.069724\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.100991\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.034085\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.107376\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.117907\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.036076\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.176281\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.075367\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.123179\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.073479\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.123025\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.176704\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.020024\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.078683\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.205316\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.099726\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.083663\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.243602\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.151551\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.091908\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.032886\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.211398\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.042125\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.051550\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.117734\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.027261\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.069006\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.163546\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.101421\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.082957\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.134693\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.101315\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.013861\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.140742\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.101273\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.115871\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.076575\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.102614\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.056085\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.151927\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.042757\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.132225\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.129050\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.069755\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.025066\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.030698\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.128241\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.042358\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.172904\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.202946\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.024921\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.034314\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.093986\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.040812\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.275769\n",
            "\n",
            "Test set: Average loss: 0.0781, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.115700\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.159891\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.084157\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.082409\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.114534\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.168364\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.240476\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.051503\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.156359\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.041403\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.107722\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.006747\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.160790\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.120371\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.040461\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.071576\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.028960\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.104348\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.081743\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.168133\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.080409\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.196245\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.054231\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.080403\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.131812\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.084675\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.094286\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.076001\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.146797\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.032616\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.267053\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.022118\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.100542\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.241978\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.067037\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.134078\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.151388\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.064772\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.220536\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.142012\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.077108\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.059847\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.032835\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.047832\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.035602\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.194868\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.153751\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.032234\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.078801\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.036398\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.159791\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.011107\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.067687\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.076065\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.042721\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.012607\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.017709\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.041356\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.044725\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.123111\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.065012\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.091001\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.083161\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.093827\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.052253\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.121559\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.035372\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.169356\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.102895\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.056024\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.159188\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.042253\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.054006\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.078829\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.076270\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.052707\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.027666\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.147481\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.102105\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.012875\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.106190\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.085543\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.043952\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.189746\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.280306\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.064627\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.056057\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.076273\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.075768\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.107013\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.028665\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.021938\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.020106\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.027112\n",
            "\n",
            "Test set: Average loss: 0.0685, Accuracy: 9784/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.057820\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.165115\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.037470\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.040103\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.020856\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.048201\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.017258\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.122846\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.114993\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.046604\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.322262\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.059720\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.043759\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.024284\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.030404\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.019994\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.110568\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.068662\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.021905\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.054378\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.017373\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.156619\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.070435\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.080143\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.038655\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.088442\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.124663\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.047805\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.045785\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.022912\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.056519\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.015752\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.040237\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.037050\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.046490\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.072268\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.189665\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.012553\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.061441\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.057284\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.076897\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.070235\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.032040\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.016338\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.047734\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.014042\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.098317\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.089698\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.241461\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.022819\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.078164\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.024222\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.159130\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.095266\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.066586\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.063557\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.021232\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.073478\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.238276\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.019604\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.035445\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.089762\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.118003\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.076584\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.047040\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.027693\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.026145\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.150196\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.013808\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.173011\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.132879\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.054927\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.042189\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.055055\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.031637\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.133017\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.055436\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.026962\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.095666\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.016448\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.202858\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.060639\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.061898\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.012719\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.040043\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.175558\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.079903\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.012311\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.056584\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.034126\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.022545\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.087674\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.378345\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.076483\n",
            "\n",
            "Test set: Average loss: 0.0613, Accuracy: 9810/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.164202\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.102500\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.017067\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.047881\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.066474\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.100150\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.183769\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.086968\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.090347\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.084641\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.172917\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.145761\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.032565\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.029026\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.042554\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.007536\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.035639\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.146887\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.261875\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.302498\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.030474\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.081499\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.019037\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.018738\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.066420\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.038974\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.022689\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.011074\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.128709\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.032931\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.032781\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.028977\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.088064\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.074526\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.110589\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.018449\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.078063\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.191684\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.059489\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.040009\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.131528\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.067261\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.103424\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.016754\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.101211\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.043693\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.021884\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.086163\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.069005\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.063699\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.039485\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.164711\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.015756\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.043159\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.020043\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.024961\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.029701\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.088259\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.018618\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.092008\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.042079\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.097001\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.062448\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.064730\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.035056\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.084534\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.143975\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.082114\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.037576\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.012485\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.046472\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.210724\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.026473\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.081646\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.074322\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.087720\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.070669\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.073368\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.125411\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.080530\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.072058\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.081103\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.052362\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.059940\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.024723\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.048846\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.035134\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.034627\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.096543\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.025712\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.037191\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.248727\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.055848\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.138423\n",
            "\n",
            "Test set: Average loss: 0.0587, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.101815\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.074411\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.019099\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.027092\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.028539\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.055592\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.079528\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.019371\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.058734\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.075036\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.132473\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.043093\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.015524\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.149736\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.201630\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.012691\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.105585\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.062413\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.032532\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.062707\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.086375\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.036326\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.125870\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.016852\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.093513\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.091858\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.115798\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.035243\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.224536\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.013099\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.013542\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.054088\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.038775\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.031732\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.009666\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.060248\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.036089\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.044971\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.010181\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.128735\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.025630\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.088048\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.026749\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.116285\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.152289\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.048042\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.125752\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.029141\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.058612\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.043716\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.008144\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.012084\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.005961\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.011044\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.030894\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.172793\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.014209\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.106960\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.017379\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.137698\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.120515\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.047227\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.116516\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.135623\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.032820\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.025315\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.011435\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.168159\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.006209\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.194949\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.091509\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.019304\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.077129\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.041079\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.081136\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.025167\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.082258\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.152403\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.102351\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.034492\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.214477\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.083395\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.069079\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.023391\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.008320\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.109958\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.109407\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.010480\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.056135\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.055276\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.011841\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.066476\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.083749\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.041710\n",
            "\n",
            "Test set: Average loss: 0.0536, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.078515\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.111863\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.040148\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.034402\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.133246\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.135164\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.044358\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.010112\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.016614\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.011208\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.023697\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.034444\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.121258\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.073405\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.020770\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.071878\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.028991\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.060369\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.150891\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.028589\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.039725\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.055759\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.035310\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.037557\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.014804\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.163907\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.043898\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.020074\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.064692\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.144497\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.067901\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.020898\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.038207\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.026312\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.059740\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.137592\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.033961\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.043845\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.034381\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.045425\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.118250\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.079885\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.126043\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.024484\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.029506\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.007451\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.050132\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.047755\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.035139\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.132446\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.014794\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.093465\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.074156\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.034883\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.202094\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.085357\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.122728\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.024437\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.011046\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.014864\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.022740\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.011270\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.050693\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.043158\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.027648\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.087456\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.017176\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.028354\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.151460\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.045556\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.074245\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.045500\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.062744\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.111121\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.005491\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.029665\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.119619\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.003355\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.065596\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.084657\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.082757\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.053398\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.010624\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.041479\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.083432\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.049943\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.081266\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.005326\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.020565\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.109341\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.107367\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.051295\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.016565\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.067223\n",
            "\n",
            "Test set: Average loss: 0.0503, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.103428\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.090951\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.022459\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.101653\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.111158\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.039981\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.072780\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.003673\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.162489\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.058297\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.025645\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.048173\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.036089\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.087676\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.054269\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.028877\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.135258\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.037477\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.011907\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.083992\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.023377\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.028539\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.036602\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.028472\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.004973\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.013079\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.074352\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.043865\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.051425\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.098851\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.011950\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.015249\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.072036\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.005156\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.040983\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.019498\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.005670\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.034260\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.034565\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.060383\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.051681\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.013333\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.038392\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.019739\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.076064\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.099842\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.079739\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.007881\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.048480\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.006277\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.048086\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.017888\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.007429\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.090440\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.042577\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.010921\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.027236\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.028643\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.131466\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.061158\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.040817\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.051448\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.022467\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.021955\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.026944\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.049203\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.020736\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.015777\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.066339\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.008608\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.014566\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.022749\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.100258\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.350156\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.009679\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.041543\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.125541\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.013950\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.022698\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.034781\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.074877\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.085804\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.011510\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.077823\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.045154\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.018423\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.013129\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.083295\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.058163\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.046699\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.204624\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.025385\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.033146\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.007377\n",
            "\n",
            "Test set: Average loss: 0.0558, Accuracy: 9822/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}